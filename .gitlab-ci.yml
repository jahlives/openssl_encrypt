default:
  image: python:3.13-alpine
  cache:
    paths:
      - .pip-cache/
  before_script:
    - python3 --version
    - pip install --upgrade pip --break-system-packages
    - pip install build twine PyYAML --break-system-packages

stages:
  - sync
  - security
  - test
  - build
  - publish

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  DOCKER_IMAGE: $CI_REGISTRY_IMAGE/python-liboqs:3.13-alpine
  DOCS_ONLY: "false"


sync-wiki:
  stage: sync
  image: alpine:latest
  before_script:
    - apk add --no-cache git
  script:
    - git clone https://oauth2:${PROJECT_ACCESS_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.wiki.git wiki
    - cp -r openssl_encrypt/docs/* wiki/
    - cd wiki
    - git config --global user.email "pipeline@rm-rf.ch"
    - git config --global user.name "GitLab Pipeline"
    - git add .
    - git diff-index --quiet HEAD || git commit -m "Update wiki from docs folder"
    - git push
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "release"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH == "dev"
      when: manual
      allow_failure: true

# Dependency security scanning
dependency-scan:
  stage: security
  image: python:3.13
  script:
    - pip install pip-audit bandit
    # Use custom script that handles dependency scanning and GitLab report generation
    - python scripts/gitlab_dependency_scan.py
    # Display results for visibility in logs
    - echo "=== Production Dependencies Scan ==="
    - cat pip-audit-prod-results.json || echo "No production scan results available"
    - echo "=== Development Dependencies Scan ==="
    - cat pip-audit-dev-results.json || echo "No development scan results available"
    - echo "=== GitLab Dependency Scanning Report ==="
    - cat gl-dependency-scanning-report.json || echo "No report available"
  artifacts:
    reports:
      dependency_scanning: gl-dependency-scanning-report.json
    paths:
      - gl-dependency-scanning-report.json
      - pip-audit-prod-results.json
      - pip-audit-dev-results.json
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Python code security scanning with Bandit
code-security-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install bandit[toml]
  script:
    # Run bandit with comprehensive security checks
    - bandit -r openssl_encrypt/ -c .bandit.yaml -f json -o gl-sast-report.json || true
    - bandit -r openssl_encrypt/ -c .bandit.yaml -f txt || true  # Display results in terminal
    - echo "=== Bandit Security Scan Results ==="
    - cat gl-sast-report.json | python -m json.tool | head -50 || echo "No issues found"
  artifacts:
    reports:
      sast: gl-sast-report.json
    paths:
      - gl-sast-report.json
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Code quality analysis with Pylint
code-quality-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install pylint pylint-json2html
    - pip install -r requirements-prod.txt  # Install dependencies for import analysis
  script:
    # Run pylint with detailed analysis
    - pylint openssl_encrypt/ --output-format=json:pylint-report.json,text:pylint-report.txt,colorized || true
    - echo "=== Pylint Code Quality Results ==="
    - cat pylint-report.txt | head -50 || echo "No issues found"
    # Generate HTML report for better visualization
    - pylint-json2html -o pylint-report.html pylint-report.json || true
  artifacts:
    paths:
      - pylint-report.json
      - pylint-report.txt
      - pylint-report.html
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Type checking with MyPy
type-checking:
  stage: security
  image: python:3.13
  before_script:
    - pip install mypy types-PyYAML types-requests
    - pip install -r requirements-prod.txt  # Install dependencies for type checking
  script:
    # Run mypy type checking
    - mypy openssl_encrypt/ --config-file mypy.ini --txt-report mypy-report --html-report mypy-html || true
    - echo "=== MyPy Type Checking Results ==="
    - cat mypy-report/index.txt | head -30 || echo "No type issues found"
  artifacts:
    paths:
      - mypy-report/
      - mypy-html/
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Advanced security scanning with Semgrep
semgrep-security-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install semgrep
  script:
    # Run Semgrep with security-focused rulesets
    - semgrep --config=auto --json --output=semgrep-report.json openssl_encrypt/ || true
    - semgrep --config=p/security-audit --json --output=semgrep-security.json openssl_encrypt/ || true
    - semgrep --config=p/python --json --output=semgrep-python.json openssl_encrypt/ || true
    - echo "=== Semgrep Security Scan Results ==="
    - cat semgrep-report.json | python -m json.tool | head -50 || echo "No issues found"
  artifacts:
    paths:
      - semgrep-report.json
      - semgrep-security.json
      - semgrep-python.json
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Code complexity and maintainability analysis
code-complexity-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install radon xenon flake8 mccabe
  script:
    # Cyclomatic complexity analysis
    - radon cc openssl_encrypt/ -j > complexity-report.json || true
    - radon cc openssl_encrypt/ -s > complexity-report.txt || true
    # Maintainability index
    - radon mi openssl_encrypt/ -j > maintainability-report.json || true
    - radon mi openssl_encrypt/ -s > maintainability-report.txt || true
    # Halstead complexity metrics
    - radon hal openssl_encrypt/ -j > halstead-report.json || true
    # Raw metrics (lines of code, etc.)
    - radon raw openssl_encrypt/ -j > raw-metrics.json || true
    - echo "=== Code Complexity Analysis Results ==="
    - cat complexity-report.txt | head -30 || echo "No complexity issues found"
    - echo "=== Maintainability Index Results ==="
    - cat maintainability-report.txt | head -20 || echo "No maintainability issues found"
  artifacts:
    paths:
      - complexity-report.json
      - complexity-report.txt
      - maintainability-report.json
      - maintainability-report.txt
      - halstead-report.json
      - raw-metrics.json
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Software Bill of Materials generation
sbom-generation:
  stage: security
  image: python:3.13
  before_script:
    - pip install cyclonedx-bom
  script:
    # cyclonedx-py command format uses positional arguments for requirements file
    - cyclonedx-py requirements requirements-prod.txt -o bom.json
    - python -c "import json; f = open('bom.json', 'r'); data = json.load(f); f.close(); print(json.dumps(data, indent=2))" | head -n 50  # Display first 50 lines as a preview
  allow_failure: true  # Allow job to succeed even if SBOM generation fails
  artifacts:
    paths:
      - bom.json
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

test:
  stage: test
  image: python:3.13-alpine  # Use standard Python image instead of custom one
  variables:
    PQC_QUIET: "true"  # Suppress PQC module initialization messages
  cache:
    key: "liboqs-cache-v2-0.12.0"  # Updated to force rebuild with liboqs 0.12.0
    paths:
      - liboqs-cache/
  before_script:
    - pip install -r requirements.txt --break-system-packages || echo "Some dependencies may have failed to install"
    - pip install pytest pytest-order setuptools --break-system-packages  # setuptools provides pkg_resources
    # Install tkinter for GUI components (fixes ImportError: libtk8.6.so)
    - apk add tk-dev tcl-dev
    # Check if we have cached liboqs build
    - |
      if [ -f "liboqs-cache/BUILT_SUCCESS" ]; then
        echo "=== Using cached liboqs build ==="
        cp -r liboqs-cache/lib/* /usr/local/lib/ || echo "No cached libraries found"
        cp -r liboqs-cache/include/* /usr/local/include/ || echo "No cached headers found"
        cp -r liboqs-cache/pkgconfig/* /usr/local/lib/pkgconfig/ || echo "No cached pkgconfig found"
        mkdir -p /usr/local/lib/pkgconfig
      else
        echo "=== Building liboqs from scratch ==="
        # Install build dependencies only when building
        apk add git gcc g++ cmake ninja make go python3-dev openssl-dev musl-dev
        # Clone liboqs repository with submodules (pinned to 0.12.0 for HQC algorithm support)
        git clone --recurse-submodules --branch 0.12.0 https://github.com/open-quantum-safe/liboqs.git
        # Build and install liboqs
        cd liboqs
        mkdir build && cd build
        cmake -GNinja -DCMAKE_INSTALL_PREFIX=/usr/local ..
        ninja
        ninja install
        # Cache the built artifacts
        cd $CI_PROJECT_DIR
        mkdir -p liboqs-cache/lib liboqs-cache/include liboqs-cache/pkgconfig
        cp -r /usr/local/lib/liboqs* liboqs-cache/lib/ || echo "No liboqs libraries to cache"
        mkdir -p liboqs-cache/lib/cmake
        cp -r /usr/local/lib/cmake/liboqs liboqs-cache/lib/cmake/ || echo "No cmake files to cache"
        cp /usr/local/lib/pkgconfig/liboqs.pc liboqs-cache/pkgconfig/ || echo "No pkgconfig to cache"
        cp -r /usr/local/include/oqs liboqs-cache/include/ || echo "No headers to cache"
        touch liboqs-cache/BUILT_SUCCESS
        echo "=== liboqs build cached ==="
      fi
    # Set up library paths so liboqs-python can find our pre-built liboqs
    - export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
    - export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
    - ldconfig || echo "ldconfig failed, continuing"
    # Install liboqs Python bindings (pinned to 0.12.0 to match liboqs version)
    - pip install --user git+https://github.com/open-quantum-safe/liboqs-python.git@0.12.0
  script:
    - export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
    - echo "=== Environment Check ==="
    - python3 --version
    - python3 -c "import oqs; print('liboqs version:', getattr(oqs, 'get_version', getattr(oqs, 'oqs_version', 'unknown'))()); print('HQC-128 available:', 'HQC-128' in oqs.get_enabled_kem_mechanisms())"
    - echo "=== Running All Tests ==="
    - python3 -m pytest openssl_encrypt/unittests/unittests.py -v
  rules:
    # Run tests on dev, testing, and release branches, and for tags
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
      # Must succeed on release branch
      allow_failure: false
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      # Must succeed on releases branches
      allow_failure: false
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"

# Fallback test job that builds liboqs from scratch
# This runs only if the main test job fails, typically due to missing image
# Remove the fallback test job since we're now using the self-contained approach in the main test job


build:
  stage: build
  needs:
    - job: test
      optional: true
  script:
    - python3 -m build
  artifacts:
    paths:
      - dist/
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"


publish:
  stage: publish
  needs:
    - job: build
      artifacts: true
  script:
    - pip install --upgrade twine --break-system-packages
    - echo "Attempting to publish with CI_JOB_TOKEN..."
    - TWINE_PASSWORD=${PROJECT_ACCESS_TOKEN} TWINE_USERNAME=oauth2 python3 -m twine upload --verbose --repository-url "https://${MY_GITLAB_PYPI}/api/v4/projects/2/packages/pypi" dist/*
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true

publish-pypi-test:
  stage: publish
  image: python:3.13-alpine
  needs:
    - job: build
      artifacts: true
  script:
    - pip install build twine --break-system-packages
    - TWINE_PASSWORD=${PYPI_API_TOKEN} TWINE_USERNAME=__token__ python3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true

publish-pypi-prod:
  stage: publish
  image: python:3.13-alpine
  needs:
    - job: build
      artifacts: true
  script:
    - pip install build twine --break-system-packages
    - TWINE_PASSWORD=${PYPI_API_TOKEN_PROD} TWINE_USERNAME=__token__ python3 -m twine upload dist/*
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
