default:
  image: python:3.13-alpine
  cache:
    paths:
      - .pip-cache/
  before_script:
    - python3 --version
    - pip install --upgrade pip --break-system-packages
    - pip install build twine PyYAML --break-system-packages

stages:
  - sync
  - security
  - dependencies
  - test
  - build
  - publish

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  DOCKER_IMAGE: $CI_REGISTRY_IMAGE/python-liboqs:3.13-alpine
  DOCS_ONLY: "false"


sync-wiki:
  stage: sync
  image: alpine:latest
  before_script:
    - apk add --no-cache git
  script:
    - git clone https://oauth2:${PROJECT_ACCESS_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.wiki.git wiki
    - cp -r openssl_encrypt/docs/* wiki/
    - cd wiki
    - git config --global user.email "pipeline@rm-rf.ch"
    - git config --global user.name "GitLab Pipeline"
    - git add .
    - git diff-index --quiet HEAD || git commit -m "Update wiki from docs folder"
    - git push
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "release"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH == "dev"
      when: manual
      allow_failure: true

# Dependency security scanning
dependency-scan:
  stage: security
  image: python:3.13
  script:
    - pip install pip-audit bandit
    # Use custom script that handles dependency scanning and GitLab report generation
    - python scripts/gitlab_dependency_scan.py
    # Display results for visibility in logs
    - echo "=== Production Dependencies Scan ==="
    - cat pip-audit-prod-results.json || echo "No production scan results available"
    - echo "=== Development Dependencies Scan ==="
    - cat pip-audit-dev-results.json || echo "No development scan results available"
    - echo "=== GitLab Dependency Scanning Report ==="
    - cat gl-dependency-scanning-report.json || echo "No report available"
  artifacts:
    reports:
      dependency_scanning: gl-dependency-scanning-report.json
    paths:
      - gl-dependency-scanning-report.json
      - pip-audit-prod-results.json
      - pip-audit-dev-results.json
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Python code security scanning with Bandit
code-security-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install bandit[toml]
  script:
    # Run bandit with comprehensive security checks
    - bandit -r openssl_encrypt/ -c .bandit.yaml -f json -o gl-sast-report.json || true
    - bandit -r openssl_encrypt/ -c .bandit.yaml -f txt || true  # Display results in terminal
    - echo "=== Bandit Security Scan Results ==="
    - cat gl-sast-report.json | python -m json.tool | head -50 || echo "No issues found"
  artifacts:
    reports:
      sast: gl-sast-report.json
    paths:
      - gl-sast-report.json
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Code quality analysis with Pylint
code-quality-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install pylint pylint-json2html
    - pip install -r requirements-prod.txt  # Install dependencies for import analysis
  script:
    # Run pylint with detailed analysis
    - pylint openssl_encrypt/ --output-format=json:pylint-report.json,text:pylint-report.txt,colorized || true
    - echo "=== Pylint Code Quality Results ==="
    - cat pylint-report.txt | head -50 || echo "No issues found"
    # Generate HTML report for better visualization
    - pylint-json2html -o pylint-report.html pylint-report.json || true
  artifacts:
    paths:
      - pylint-report.json
      - pylint-report.txt
      - pylint-report.html
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Type checking with MyPy
type-checking:
  stage: security
  image: python:3.13
  before_script:
    - pip install mypy types-PyYAML types-requests
    - pip install -r requirements-prod.txt  # Install dependencies for type checking
  script:
    # Run mypy type checking
    - mypy openssl_encrypt/ --config-file mypy.ini --txt-report mypy-report --html-report mypy-html || true
    - echo "=== MyPy Type Checking Results ==="
    - cat mypy-report/index.txt | head -30 || echo "No type issues found"
  artifacts:
    paths:
      - mypy-report/
      - mypy-html/
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Advanced security scanning with Semgrep
semgrep-security-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install semgrep
  script:
    # Run Semgrep with security-focused rulesets
    - semgrep --config=auto --json --output=semgrep-report.json openssl_encrypt/ || true
    - semgrep --config=p/security-audit --json --output=semgrep-security.json openssl_encrypt/ || true
    - semgrep --config=p/python --json --output=semgrep-python.json openssl_encrypt/ || true
    - echo "=== Semgrep Security Scan Results ==="
    - cat semgrep-report.json | python -m json.tool | head -50 || echo "No issues found"
  artifacts:
    paths:
      - semgrep-report.json
      - semgrep-security.json
      - semgrep-python.json
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Code complexity and maintainability analysis
code-complexity-scan:
  stage: security
  image: python:3.13
  before_script:
    - pip install radon xenon flake8 mccabe
  script:
    # Cyclomatic complexity analysis
    - radon cc openssl_encrypt/ -j > complexity-report.json || true
    - radon cc openssl_encrypt/ -s > complexity-report.txt || true
    # Maintainability index
    - radon mi openssl_encrypt/ -j > maintainability-report.json || true
    - radon mi openssl_encrypt/ -s > maintainability-report.txt || true
    # Halstead complexity metrics
    - radon hal openssl_encrypt/ -j > halstead-report.json || true
    # Raw metrics (lines of code, etc.)
    - radon raw openssl_encrypt/ -j > raw-metrics.json || true
    - echo "=== Code Complexity Analysis Results ==="
    - cat complexity-report.txt | head -30 || echo "No complexity issues found"
    - echo "=== Maintainability Index Results ==="
    - cat maintainability-report.txt | head -20 || echo "No maintainability issues found"
  artifacts:
    paths:
      - complexity-report.json
      - complexity-report.txt
      - maintainability-report.json
      - maintainability-report.txt
      - halstead-report.json
      - raw-metrics.json
    expire_in: 1 week
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "nightly" && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Software Bill of Materials generation
sbom-generation:
  stage: security
  image: python:3.13
  before_script:
    - pip install cyclonedx-bom
  script:
    # cyclonedx-py command format uses positional arguments for requirements file
    - cyclonedx-py requirements requirements-prod.txt -o bom.json
    - python -c "import json; f = open('bom.json', 'r'); data = json.load(f); f.close(); print(json.dumps(data, indent=2))" | head -n 50  # Display first 50 lines as a preview
  allow_failure: true  # Allow job to succeed even if SBOM generation fails
  artifacts:
    paths:
      - bom.json
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"

# Build liboqs library and cache it for use in tests
# NOTE: Currently disabled while testing Alpine image approach
# build-liboqs:
#   stage: dependencies
#   image: python:3.11-slim  # Use same Debian-based image as test
#   cache:
#     key: "liboqs-cache-v5-debian-0.12.0"  # Same cache key as test job
#     paths:
#       - liboqs-cache/
#   before_script:
#     - apt-get update
#     # Install build dependencies (needed for liboqs compilation)
#     - apt-get install -y git gcc g++ cmake ninja-build make golang-go python3-dev libssl-dev
#   script:
#     - echo "=== Cache Debug ==="
#     - ls -la liboqs-cache/ || echo "No cache directory found"
#     - |
#       if [ -f "liboqs-cache/BUILT_SUCCESS" ]; then
#         echo "=== liboqs already cached, skipping build ==="
#         ls -la liboqs-cache/
#       else
#         echo "=== Building liboqs from scratch ==="
#         git clone --recurse-submodules --branch 0.12.0 https://github.com/open-quantum-safe/liboqs.git
#         cd liboqs && mkdir build && cd build
#         cmake -GNinja -DCMAKE_INSTALL_PREFIX=/usr/local -DBUILD_SHARED_LIBS=ON -DOQS_USE_OPENSSL=ON ..
#         ninja && ninja install
#         cd $CI_PROJECT_DIR
#         mkdir -p liboqs-cache/lib liboqs-cache/include liboqs-cache/pkgconfig liboqs-cache/lib/cmake
#         cp -r /usr/local/lib/liboqs* liboqs-cache/lib/ || echo "No liboqs libraries to cache"
#         cp -r /usr/local/lib/cmake/liboqs liboqs-cache/lib/cmake/ || echo "No cmake files to cache"
#         cp /usr/local/lib/pkgconfig/liboqs.pc liboqs-cache/pkgconfig/ || echo "No pkgconfig to cache"
#         cp -r /usr/local/include/oqs liboqs-cache/include/ || echo "No headers to cache"
#         touch liboqs-cache/BUILT_SUCCESS
#         echo "=== liboqs build cached ==="
#       fi
#     - echo "=== Build artifacts summary ==="
#     - ls -la liboqs-cache/
#     - du -sh liboqs-cache/
#   rules:
#     # Build liboqs for the same conditions as test job
#     - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
#     - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
#     - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
#     - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
#     - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
#     - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $DOCS_ONLY != "true"
#     - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"

test:
  stage: test
  image: $CI_REGISTRY_IMAGE/python-liboqs:3.13-alpine  # Switch back to original Alpine image to test
  # NOTE: Removed needs: [build-liboqs] - Alpine image already has liboqs pre-built
  variables:
    PQC_QUIET: "true"  # Suppress PQC module initialization messages
  # NOTE: Removed cache - Alpine image already has liboqs, no need to restore cache
  before_script:
    - apk update  # Alpine uses apk, not apt-get
    - apk add tk-dev tcl-dev  # Alpine packages for tkinter
    - pip install -r requirements.txt --break-system-packages || echo "Some dependencies may have failed to install"
    - pip install pytest pytest-order setuptools --break-system-packages
  script:
    # Alpine image already has liboqs pre-built, just run tests
    - echo "=== Using pre-built Alpine image with liboqs ==="
    - echo "=== Runtime Library Debug ==="
    - ldd /usr/local/lib/liboqs.so || echo "No liboqs.so found"
    - ls -la /usr/local/lib/liboqs* || echo "No liboqs libraries"
    - echo "=== Environment Check ==="
    - python3 --version
    - python3 -c "import oqs; print('liboqs version:', getattr(oqs, 'get_version', getattr(oqs, 'oqs_version', 'unknown'))()); print('HQC-128 available:', 'HQC-128' in oqs.get_enabled_kem_mechanisms())"
    - echo "=== Running All Tests ==="
    - python3 -c "import os; print('PYTEST_CURRENT_TEST env var support:', 'PYTEST_CURRENT_TEST' in os.environ)"
    - python3 -m pytest openssl_encrypt/unittests/unittests.py -v
  rules:
    # Run tests on dev, testing, and release branches, and for tags
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
      # Must succeed on release branch
      allow_failure: false
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      # Must succeed on releases branches
      allow_failure: false
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"

# Fallback test job that builds liboqs from scratch
# This runs only if the main test job fails, typically due to missing image
# Remove the fallback test job since we're now using the self-contained approach in the main test job


build:
  stage: build
  needs:
    - job: test
      optional: true
  script:
    - python3 -m build
  artifacts:
    paths:
      - dist/
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "main" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "release" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "testing" && $DOCS_ONLY != "true"
    - if: $CI_COMMIT_BRANCH == "dev" && $DOCS_ONLY != "true"


publish:
  stage: publish
  needs:
    - job: build
      artifacts: true
  script:
    - pip install --upgrade twine --break-system-packages
    - echo "Attempting to publish with CI_JOB_TOKEN..."
    - TWINE_PASSWORD=${PROJECT_ACCESS_TOKEN} TWINE_USERNAME=oauth2 python3 -m twine upload --verbose --repository-url "https://${MY_GITLAB_PYPI}/api/v4/projects/2/packages/pypi" dist/*
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true

publish-pypi-test:
  stage: publish
  image: python:3.13-alpine
  needs:
    - job: build
      artifacts: true
  script:
    - pip install build twine --break-system-packages
    - TWINE_PASSWORD=${PYPI_API_TOKEN} TWINE_USERNAME=__token__ python3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true

publish-pypi-prod:
  stage: publish
  image: python:3.13-alpine
  needs:
    - job: build
      artifacts: true
  script:
    - pip install build twine --break-system-packages
    - TWINE_PASSWORD=${PYPI_API_TOKEN_PROD} TWINE_USERNAME=__token__ python3 -m twine upload dist/*
  rules:
    - if: $CI_COMMIT_TAG && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
    - if: $CI_COMMIT_BRANCH =~ /^releases\/.*/ && $DOCS_ONLY != "true"
      when: manual
      allow_failure: true
